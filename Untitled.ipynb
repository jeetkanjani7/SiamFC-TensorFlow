{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "slim = tf.contrib.slim\n",
    "\n",
    "from tensorflow.contrib.rnn import LSTMCell, MultiRNNCell\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import siamese_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_training = False\n",
    "trainable = True\n",
    "embed_config = dict()\n",
    "\n",
    "inputs = tf.get_variable(\"input\", shape = [8, 127,127, 3])\n",
    "reuse=None\n",
    "scope='convolutional_alexnet'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope(scope, 'convolutional_alexnet', [inputs], reuse=reuse) as sc:\n",
    "    end_points_collection = sc.name + '_end_points'\n",
    "    with slim.arg_scope([slim.conv2d, slim.max_pool2d],\n",
    "                        outputs_collections=end_points_collection):\n",
    "        net = inputs\n",
    "        net = slim.conv2d(net, 96, [11, 11], 2, scope='conv1')\n",
    "        net = slim.max_pool2d(net, [3, 3], 2, scope='pool1')\n",
    "        with tf.variable_scope('conv2'):\n",
    "            b1, b2 = tf.split(net, 2, 3)\n",
    "            b1 = slim.conv2d(b1, 128, [5, 5], scope='b1')\n",
    "            # The original implementation has bias terms for all convolution, but\n",
    "            # it actually isn't necessary if the convolution layer is followed by a batch\n",
    "            # normalization layer since batch norm will subtract the mean.\n",
    "            b2 = slim.conv2d(b2, 128, [5, 5], scope='b2')\n",
    "            net = tf.concat([b1, b2], 3)\n",
    "        net = slim.max_pool2d(net, [3, 3], 2, scope='pool2')\n",
    "        net = slim.conv2d(net, 384, [3, 3], 1, scope='conv3')\n",
    "        with tf.variable_scope('conv4'):\n",
    "            b1, b2 = tf.split(net, 2, 3)\n",
    "            b1 = slim.conv2d(b1, 192, [3, 3], 1, scope='b1')\n",
    "            b2 = slim.conv2d(b2, 192, [3, 3], 1, scope='b2')\n",
    "            net = tf.concat([b1, b2], 3)\n",
    "          # Conv 5 with only convolution, has bias\n",
    "        with tf.variable_scope('conv5'):\n",
    "            with slim.arg_scope([slim.conv2d],\n",
    "                            activation_fn=None, normalizer_fn=None):\n",
    "                b1, b2 = tf.split(net, 2, 3)\n",
    "                b1 = slim.conv2d(b1, 128, [3, 3], 1, scope='b1')\n",
    "                b2 = slim.conv2d(b2, 128, [3, 3], 1, scope='b2')\n",
    "                net = tf.concat([b1, b2], 3)\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(8), Dimension(15), Dimension(15), Dimension(256)])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(64), Dimension(None), Dimension(None), Dimension(256)])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = tf.reshape(output, [64,-1,-1,256])\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_op = tf.global_variables_initializer()\n",
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(init_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m \u001b[0msiamese_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSiameseModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m      <no docstring>\n",
       "\u001b[0;31mFile:\u001b[0m           ~/Tonbo/SiamFC-TensorFlow/siamese_model.py\n",
       "\u001b[0;31mType:\u001b[0m           classobj\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = siamese_model.SiameseModel(model_config, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = siamese_model.SiameseModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdynamic_rnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msequence_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparallel_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswap_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_major\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscope\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Creates a recurrent neural network specified by RNNCell `cell`.\n",
       "\n",
       "Performs fully dynamic unrolling of `inputs`.\n",
       "\n",
       "Example:\n",
       "\n",
       "```python\n",
       "# create a BasicRNNCell\n",
       "rnn_cell = tf.nn.rnn_cell.BasicRNNCell(hidden_size)\n",
       "\n",
       "# 'outputs' is a tensor of shape [batch_size, max_time, cell_state_size]\n",
       "\n",
       "# defining initial state\n",
       "initial_state = rnn_cell.zero_state(batch_size, dtype=tf.float32)\n",
       "\n",
       "# 'state' is a tensor of shape [batch_size, cell_state_size]\n",
       "outputs, state = tf.nn.dynamic_rnn(rnn_cell, input_data,\n",
       "                                   initial_state=initial_state,\n",
       "                                   dtype=tf.float32)\n",
       "```\n",
       "\n",
       "```python\n",
       "# create 2 LSTMCells\n",
       "rnn_layers = [tf.nn.rnn_cell.LSTMCell(size) for size in [128, 256]]\n",
       "\n",
       "# create a RNN cell composed sequentially of a number of RNNCells\n",
       "multi_rnn_cell = tf.nn.rnn_cell.MultiRNNCell(rnn_layers)\n",
       "\n",
       "# 'outputs' is a tensor of shape [batch_size, max_time, 256]\n",
       "# 'state' is a N-tuple where N is the number of LSTMCells containing a\n",
       "# tf.contrib.rnn.LSTMStateTuple for each cell\n",
       "outputs, state = tf.nn.dynamic_rnn(cell=multi_rnn_cell,\n",
       "                                   inputs=data,\n",
       "                                   dtype=tf.float32)\n",
       "```\n",
       "\n",
       "\n",
       "Args:\n",
       "  cell: An instance of RNNCell.\n",
       "  inputs: The RNN inputs.\n",
       "    If `time_major == False` (default), this must be a `Tensor` of shape:\n",
       "      `[batch_size, max_time, ...]`, or a nested tuple of such\n",
       "      elements.\n",
       "    If `time_major == True`, this must be a `Tensor` of shape:\n",
       "      `[max_time, batch_size, ...]`, or a nested tuple of such\n",
       "      elements.\n",
       "    This may also be a (possibly nested) tuple of Tensors satisfying\n",
       "    this property.  The first two dimensions must match across all the inputs,\n",
       "    but otherwise the ranks and other shape components may differ.\n",
       "    In this case, input to `cell` at each time-step will replicate the\n",
       "    structure of these tuples, except for the time dimension (from which the\n",
       "    time is taken).\n",
       "    The input to `cell` at each time step will be a `Tensor` or (possibly\n",
       "    nested) tuple of Tensors each with dimensions `[batch_size, ...]`.\n",
       "  sequence_length: (optional) An int32/int64 vector sized `[batch_size]`.\n",
       "    Used to copy-through state and zero-out outputs when past a batch\n",
       "    element's sequence length.  So it's more for correctness than performance.\n",
       "  initial_state: (optional) An initial state for the RNN.\n",
       "    If `cell.state_size` is an integer, this must be\n",
       "    a `Tensor` of appropriate type and shape `[batch_size, cell.state_size]`.\n",
       "    If `cell.state_size` is a tuple, this should be a tuple of\n",
       "    tensors having shapes `[batch_size, s] for s in cell.state_size`.\n",
       "  dtype: (optional) The data type for the initial state and expected output.\n",
       "    Required if initial_state is not provided or RNN state has a heterogeneous\n",
       "    dtype.\n",
       "  parallel_iterations: (Default: 32).  The number of iterations to run in\n",
       "    parallel.  Those operations which do not have any temporal dependency\n",
       "    and can be run in parallel, will be.  This parameter trades off\n",
       "    time for space.  Values >> 1 use more memory but take less time,\n",
       "    while smaller values use less memory but computations take longer.\n",
       "  swap_memory: Transparently swap the tensors produced in forward inference\n",
       "    but needed for back prop from GPU to CPU.  This allows training RNNs\n",
       "    which would typically not fit on a single GPU, with very minimal (or no)\n",
       "    performance penalty.\n",
       "  time_major: The shape format of the `inputs` and `outputs` Tensors.\n",
       "    If true, these `Tensors` must be shaped `[max_time, batch_size, depth]`.\n",
       "    If false, these `Tensors` must be shaped `[batch_size, max_time, depth]`.\n",
       "    Using `time_major = True` is a bit more efficient because it avoids\n",
       "    transposes at the beginning and end of the RNN calculation.  However,\n",
       "    most TensorFlow data is batch-major, so by default this function\n",
       "    accepts input and emits output in batch-major form.\n",
       "  scope: VariableScope for the created subgraph; defaults to \"rnn\".\n",
       "\n",
       "Returns:\n",
       "  A pair (outputs, state) where:\n",
       "\n",
       "  outputs: The RNN output `Tensor`.\n",
       "\n",
       "    If time_major == False (default), this will be a `Tensor` shaped:\n",
       "      `[batch_size, max_time, cell.output_size]`.\n",
       "\n",
       "    If time_major == True, this will be a `Tensor` shaped:\n",
       "      `[max_time, batch_size, cell.output_size]`.\n",
       "\n",
       "    Note, if `cell.output_size` is a (possibly nested) tuple of integers\n",
       "    or `TensorShape` objects, then `outputs` will be a tuple having the\n",
       "    same structure as `cell.output_size`, containing Tensors having shapes\n",
       "    corresponding to the shape data in `cell.output_size`.\n",
       "\n",
       "  state: The final state.  If `cell.state_size` is an int, this\n",
       "    will be shaped `[batch_size, cell.state_size]`.  If it is a\n",
       "    `TensorShape`, this will be shaped `[batch_size] + cell.state_size`.\n",
       "    If it is a (possibly nested) tuple of ints or `TensorShape`, this will\n",
       "    be a tuple having the corresponding shapes. If cells are `LSTMCells`\n",
       "    `state` will be a tuple containing a `LSTMStateTuple` for each cell.\n",
       "\n",
       "Raises:\n",
       "  TypeError: If `cell` is not an instance of RNNCell.\n",
       "  ValueError: If inputs is None or an empty list.\n",
       "\u001b[0;31mFile:\u001b[0m      ~/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/ops/rnn.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tf.nn.dynamic_rnn?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m \u001b[0mLSTMCell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_units\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_peepholes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell_clip\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_proj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproj_clip\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_unit_shards\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_proj_shards\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforget_bias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_is_tuple\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreuse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m     \n",
       "Long short-term memory unit (LSTM) recurrent network cell.\n",
       "\n",
       "The default non-peephole implementation is based on:\n",
       "\n",
       "  http://www.bioinf.jku.at/publications/older/2604.pdf\n",
       "\n",
       "S. Hochreiter and J. Schmidhuber.\n",
       "\"Long Short-Term Memory\". Neural Computation, 9(8):1735-1780, 1997.\n",
       "\n",
       "The peephole implementation is based on:\n",
       "\n",
       "  https://research.google.com/pubs/archive/43905.pdf\n",
       "\n",
       "Hasim Sak, Andrew Senior, and Francoise Beaufays.\n",
       "\"Long short-term memory recurrent neural network architectures for\n",
       " large scale acoustic modeling.\" INTERSPEECH, 2014.\n",
       "\n",
       "The class uses optional peep-hole connections, optional cell clipping, and\n",
       "an optional projection layer.\n",
       "\u001b[0;31mInit docstring:\u001b[0m\n",
       "Initialize the parameters for an LSTM cell.\n",
       "\n",
       "Args:\n",
       "  num_units: int, The number of units in the LSTM cell.\n",
       "  use_peepholes: bool, set True to enable diagonal/peephole connections.\n",
       "  cell_clip: (optional) A float value, if provided the cell state is clipped\n",
       "    by this value prior to the cell output activation.\n",
       "  initializer: (optional) The initializer to use for the weight and\n",
       "    projection matrices.\n",
       "  num_proj: (optional) int, The output dimensionality for the projection\n",
       "    matrices.  If None, no projection is performed.\n",
       "  proj_clip: (optional) A float value.  If `num_proj > 0` and `proj_clip` is\n",
       "    provided, then the projected values are clipped elementwise to within\n",
       "    `[-proj_clip, proj_clip]`.\n",
       "  num_unit_shards: Deprecated, will be removed by Jan. 2017.\n",
       "    Use a variable_scope partitioner instead.\n",
       "  num_proj_shards: Deprecated, will be removed by Jan. 2017.\n",
       "    Use a variable_scope partitioner instead.\n",
       "  forget_bias: Biases of the forget gate are initialized by default to 1\n",
       "    in order to reduce the scale of forgetting at the beginning of\n",
       "    the training. Must set it manually to `0.0` when restoring from\n",
       "    CudnnLSTM trained checkpoints.\n",
       "  state_is_tuple: If True, accepted and returned states are 2-tuples of\n",
       "    the `c_state` and `m_state`.  If False, they are concatenated\n",
       "    along the column axis.  This latter behavior will soon be deprecated.\n",
       "  activation: Activation function of the inner states.  Default: `tanh`.\n",
       "  reuse: (optional) Python boolean describing whether to reuse variables\n",
       "    in an existing scope.  If not `True`, and the existing scope already has\n",
       "    the given variables, an error is raised.\n",
       "  name: String, the name of the layer. Layers with the same name will\n",
       "    share weights, but to avoid mistakes we require reuse=True in such\n",
       "    cases.\n",
       "\n",
       "  When restoring from CudnnLSTM-trained checkpoints, use\n",
       "  `CudnnCompatibleLSTMCell` instead.\n",
       "\u001b[0;31mFile:\u001b[0m           ~/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/ops/rnn_cell_impl.py\n",
       "\u001b[0;31mType:\u001b[0m           type\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "LSTMCell?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
